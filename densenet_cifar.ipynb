{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description: Classification tutorial using DenseNet\n",
        "\n"
      ],
      "metadata": {
        "id": "N-ICsaTbEC5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConfig:\n",
        "    def __init__(self):\n",
        "        # Transform\n",
        "        self.p_blur = 0.5 # ぼかしを入れる確率\n",
        "\n",
        "        # condition\n",
        "        self.batch_size = 16\n",
        "        self.lr = 5e-6\n",
        "        self.device = \"cuda\"\n",
        "        self.num_epochs = 100\n",
        "\n",
        "        # Data\n",
        "        self.val_ratio = 0.2\n",
        "\n",
        "        # DenseNet-121\n",
        "        self.growth_rate=32\n",
        "        self.block_config=(6, 12, 24, 16)"
      ],
      "metadata": {
        "id": "hK03d6beIACu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モジュールインポート"
      ],
      "metadata": {
        "id": "OjzoiU3-EeJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = MyConfig()"
      ],
      "metadata": {
        "id": "wcR0R_huEgxP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの読み込み"
      ],
      "metadata": {
        "id": "XaRK-YJVEMh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# インポート\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7nwV69l-Gquj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomBlur(torch.nn.Module):\n",
        "    def __init__(self, p=config.p_blur):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.blur = transforms.GaussianBlur(kernel_size=3)\n",
        "    def __call__(self, img):\n",
        "        if torch.rand(1) < self.p: # True\n",
        "            return self.blur(img)\n",
        "        return img # False"
      ],
      "metadata": {
        "id": "eJPXzXDbHvBM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST"
      ],
      "metadata": {
        "id": "vx65g223GwlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Transform\n",
        "# train_transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
        "#     transforms.Normalize(mean=[0.445], std=[0.269]),  # 正規化\n",
        "#     RandomBlur(), # Random Blur\n",
        "# ])\n",
        "\n",
        "# test_transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
        "#     transforms.Normalize(mean=[0.445], std=[0.269]),  # 正規化\n",
        "# ])"
      ],
      "metadata": {
        "id": "qoBfMhGdIfzi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # MNIST を取得\n",
        "# # Train\n",
        "# train_dataset = datasets.MNIST(\n",
        "#     root='data',          # データを保存するディレクトリ\n",
        "#     train=True,           # 学習用データを取得\n",
        "#     download=True,        # データがない場合はダウンロードする\n",
        "#     transform=train_transform,  # 画像データの変換方法を指定\n",
        "# )\n",
        "\n",
        "# # Validation\n",
        "# val_dataset = datasets.MNIST(\n",
        "#     root='data',\n",
        "#     train=True,\n",
        "#     download=True,\n",
        "#     transform=test_transform,\n",
        "# )\n",
        "\n",
        "# # test\n",
        "# test_dataset = datasets.MNIST(\n",
        "#     root='data',\n",
        "#     train=False,\n",
        "#     download=True,\n",
        "#     transform=test_transform,\n",
        "# )"
      ],
      "metadata": {
        "id": "e4nDBkupHDC6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR-10"
      ],
      "metadata": {
        "id": "0ttRfuQNJQug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HnctevecD_As"
      },
      "outputs": [],
      "source": [
        "# Transform\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225)),  # 正規化\n",
        "    RandomBlur(), # Random Blur\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225)),  # 正規化\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 を取得\n",
        "# Train\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root='data',          # データを保存するディレクトリ\n",
        "    train=True,           # 学習用データを取得\n",
        "    download=True,        # データがない場合はダウンロードする\n",
        "    transform=train_transform,  # 画像データの変換方法を指定\n",
        ")\n",
        "\n",
        "# Validation\n",
        "val_dataset = datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=test_transform,\n",
        ")\n",
        "\n",
        "# test\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yugesBA5HpyQ",
        "outputId": "b4671873-7e5c-4c3b-e1b8-28af3cd42f90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 28.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "データセットを分割するための2つの排反なインデックス集合を生成する関数\n",
        "dataset    : 分割対象のデータセット\n",
        "ratio      : 1つ目のセットに含めるデータ量の割合\n",
        "random_seed: 分割結果を不変にするためのシード\n",
        "'''\n",
        "def generate_subset(dataset: Dataset, ratio: float,\n",
        "                    random_seed: int=0):\n",
        "    # サブセットの大きさを計算\n",
        "    size = int(len(dataset) * ratio)\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    # 二つのセットに分ける前にシャッフル\n",
        "    random.seed(random_seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # セット1とセット2のサンプルのインデックスに分割\n",
        "    indices1, indices2 = indices[:size], indices[size:]\n",
        "\n",
        "    return indices1, indices2"
      ],
      "metadata": {
        "id": "QungSkpMMqDw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, val 分割\n",
        "val_set, train_set = generate_subset(\n",
        "    train_dataset, config.val_ratio)\n",
        "\n",
        "print(f'学習セットのサンプル数　: {len(train_set)}')\n",
        "print(f'検証セットのサンプル数　: {len(val_set)}')\n",
        "print(f'テストセットのサンプル数: {len(test_dataset)}')\n",
        "\n",
        "# インデックス集合から無作為にインデックスをサンプルするサンプラー\n",
        "train_sampler = SubsetRandomSampler(train_set)\n",
        "\n",
        "# DataLoaderを生成\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=config.batch_size, sampler=train_sampler)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=config.batch_size, sampler=val_set)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=config.batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyDxqWWSKQ5j",
        "outputId": "3c5d69d2-c743-41d6-9917-1047602bf24e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習セットのサンプル数　: 40000\n",
            "検証セットのサンプル数　: 10000\n",
            "テストセットのサンプル数: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader確認\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "    # print(images.shape) # [B, C, H, W]\n",
        "    # print(labels.shape) # [B]\n",
        "\n",
        "    image_0 = images[0]\n",
        "    label_0 = labels[0]\n",
        "\n",
        "    # tensorをnumpyに変換し、チャンネル次元を削除\n",
        "    # plt.imshow(image_0.squeeze(), cmap='gray') # for MNIST\n",
        "    plt.imshow(image_0.permute(1, 2, 0)) # for CIFAR-10\n",
        "    plt.title(f\"Label: {label_0}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "YmjU2ByUM4d9",
        "outputId": "bcbce2ab-a54c-4cc1-97e1-e9c64027920e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.112485..2.64].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEUdJREFUeJzt3Huw13Wdx/H3j5soKiELBroKDJLQpqEsOIZ5UBOTNiEvmK0u7UTjZYtt10sWIBWpbJqMYuqumpa0VorkCKtuq1gZC+J1QBA00QTlGiCSoPHbP5p9TwbV9yMczjnyeMz4z5nX+fA5M8iT7wG+tXq9Xg8AiIhWTX0BAJoPUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUeA9aenSpVGr1eKqq67aaWfOmjUrarVazJo1a6edCc2NKNBs3HbbbVGr1WLevHlNfZVG0aNHj6jVatv975BDDmnq60FERLRp6gvA7mLy5MmxcePGd3zspZdeirFjx8aJJ57YRLeCdxIF2EWGDx++zccmTpwYERGf+cxndvFtYPt8+4gWZcuWLTF+/Pg48sgjo2PHjtGhQ4c45phj4uGHH/6Tn3PNNdfEwQcfHHvuuWcce+yxMX/+/G02ixYtitNOOy3222+/aN++fQwYMCDuvffev3ifTZs2xaJFi2L16tXv6uv5wQ9+ED179oyjjz76XX0+7GyiQIuyYcOGuPnmm6OhoSEmTZoUEyZMiFWrVsXQoUPjqaee2mb/ve99L6699tq44IIL4tJLL4358+fHcccdFytWrMjNggUL4qijjoqFCxfGl7/85bj66qujQ4cOMXz48Ljnnnv+7H3mzp0bffv2jSlTphR/LU8++WQsXLgwzjrrrOLPhcbi20e0KJ06dYqlS5dGu3bt8mOjR4+OQw89NK677rq45ZZb3rF//vnnY8mSJXHAAQdERMRJJ50UgwYNikmTJsW3v/3tiIgYM2ZMHHTQQfHYY4/FHnvsERER559/fgwePDguueSSGDFiRKN8LVOnTo0I3zqiefGkQIvSunXrDMLWrVtj7dq18fbbb8eAAQPiiSee2GY/fPjwDEJExMCBA2PQoEExc+bMiIhYu3ZtPPTQQ3HGGWfE66+/HqtXr47Vq1fHmjVrYujQobFkyZJYtmzZn7xPQ0ND1Ov1mDBhQtHXsXXr1rjzzjujf//+0bdv36LPhcYkCrQ4t99+exx22GHRvn376Ny5c3Tp0iVmzJgR69ev32a7vb/q2adPn1i6dGlE/P5Jol6vx7hx46JLly7v+O+yyy6LiIiVK1fu9K/hkUceiWXLlnlKoNnx7SNalDvuuCNGjRoVw4cPj4suuii6du0arVu3jiuuuCJeeOGF4vO2bt0aEREXXnhhDB06dLub3r1779Cdt2fq1KnRqlWr+PSnP73Tz4YdIQq0KHfddVf06tUrpk2bFrVaLT/+/7+r/2NLlizZ5mOLFy+OHj16REREr169IiKibdu2ccIJJ+z8C2/H5s2b4+67746Ghobo3r37LvkxoSrfPqJFad26dURE1Ov1/NicOXNi9uzZ291Pnz79HX8mMHfu3JgzZ058/OMfj4iIrl27RkNDQ9x0003x6quvbvP5q1at+rP3eTd/JXXmzJmxbt063zqiWfKkQLNz6623xv3337/Nx8eMGROf+MQnYtq0aTFixIgYNmxYvPjii3HjjTdGv379tvnXwhG//9bP4MGD47zzzovNmzfH5MmTo3PnznHxxRfn5vrrr4/BgwfHhz70oRg9enT06tUrVqxYEbNnz45XXnklnn766T9517lz58aQIUPisssuq/yHzVOnTo099tgjTj311Ep72JVEgWbnhhtu2O7HR40aFaNGjYrXXnstbrrppnjggQeiX79+cccdd8SPf/zj7b6o7pxzzolWrVrF5MmTY+XKlTFw4MCYMmVKdOvWLTf9+vWLefPmxde+9rW47bbbYs2aNdG1a9fo379/jB8/fqd+bRs2bIgZM2bEsGHDomPHjjv1bNgZavU/fA4HYLfmzxQASKIAQBIFAJIoAJBEAYAkCgCkyv9O4Q9fKQBAy1PlXyB4UgAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKbpr4AlBlZfdru9LKjt5xfto+VhXto/jwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkWr1er1ca1mqNfReo4NfVp1ccWHb0pZPL9vGlwj00rSq/3HtSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpTVNfAMpsqT79TeHRfYaW7RcXng8tgCcFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDk3Ue0MPdXny4+v+zonn3L9t59xHuQJwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkLzmghZmeeXlwGPLTn7s1bJ9/YGS31NtLTscmognBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5N1HtCjd46DK2wsHl539bz8q28/zPiPegzwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAk7z6iEbStvOwWw4tO/saVJ1Xenj6g6Oh48OHXi/bzyo6HFsGTAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIXnNBI+hZeXnE4OqvrYiIOOeSg0ovU1nnTrVGOxtaCk8KACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpmbz7aL/C/dpGuQU7y+LKy+ff2FR0cmP+hP3IIXs34unQMnhSACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpmbzmwmsrdlfv/+AhTX2F1P75NYWf0a5gu6XwbGganhQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFIzefcRu6t99t+rqa+QDl6/vmh/SXy08rbvX/UsOvut93WtvF3w6ptFZ695o1Z522GvTkVnP7jp0crbX8XMorPZNTwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYBU+TUXJ5z+d0UHd9inY+Vtx7+uvo2I2HO/6m/nuOeWu4rOXvnMsqI9O2bhwicLP+OYRrlHRESf3r2K9ld87uLK29rZHyu7TMFv1/7nuz8vOvr2W39SefvkprlFZ/8qyva7hb27lO03ri0Y/67s7Ao8KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApFq9Xq839SWak5GnfqHy9kfTpjTaPTrHiUX7Sw44u2hfb139/SpfefmqorN/F78u2pc47vz7Km+/87lhRWd/4I3Cy7xdsG0oPPtX1ad3/2vZ+73OnT628nZ1PFd0dovVd0jRfMWzD1Xedi28yrqC7WuFZx9aYeNJAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgeffRDjj6gxcW7Wc/+8vK23EHVH8HU0TEP51c9q6kl196tPL2Hx7856Kzn40Xi/aNZd92/1K0n/3VK4v2/fq2rT5ev7Lo7Jl33Fx5+9lHvlF09sp4s2i/O+h1ytVF+xeml/3cakk8KQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5DUXO2Du42X7yz/1zcrbri9vKjp76PsPKto/+9r9lbfjY3rR2S3VR6LstSWf79678nbG8slFZ/8oFhXt2VEHFq231H9deVvwMpRmwZMCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBq09QXaMkGHlm279mzW+Xt918eW3T2m6/1KbtLdCza7w4ejavK9ssb6SK7iU+NvLVov2DlmqL9cw9fVLB+pejszv0mVt5ueLbs/+Wm5kkBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACSvudiFuhy0f+Xtmni16Oyfxcai/dGdvlh5++HfLCg6+6l4oWi/ezikaN0lqr8SZVX8rPQyjahv5eV37/xs0cn7Ft7kqDOr//8254fnFJ39+sJxlbefvGBw0dn3Xt9QtN/ZPCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKRavV6vN/UldhfPzKq+PXxI98LTy96VdHqcXHl7d/y06OytsaVo33x8oGh9/EfGVN5+//7zis7utnf17VXjflF09kUTjynaN5YHFpf90nNi2eujinQ6fGzRft0z3yxYtys6+5afbq68/cfji46uxJMCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEhec7ELzZ1dfTvo6LJXLkQsLtzvBtqdUjQ/d+y4ov0N444s2jeWjW+V7fdpd3jB+pmywwscNmJi0f7paV9tpJuU6zrg8srbVY9PKDq7bY9LK2+P/1hD0dn/9e9D/uLGkwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQGrT1BfYnfz3L56rvG0dBxed/btm9e6jPpWX190zp+jk405+X+Vt53ZFR8f+ZfNmY++2ZfsjGs6uvH1iVtn7iSIOrLxc+OySopNnLS+7SUP3sn2JlfO+Unn7+YmnFp29fNnKytu3tmwuOrsKTwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAINXq9Xq9qS/RUj21tmx/yzVzK2/bv1V29oM/mVG0f2bR18t+gAJnXXhf5e3Ubw1rtHuwfZ/7+uOVt5t+u67o7E+eenzl7c9/Nq/o7A/371+0Hz2kddGe3/OkAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ2jT1BVqy/fcr259w2sDK21MOLzv7W1dWPzsi4m+Gda68XTDz9qKz9+95YNGeXav3oYdW3g45vkPR2YOq/7SKMwcMKDr7f9cUzXmXPCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACTvPtoB3Qr3G7dU3/6m8OxOhfv5M75YeXvSF8q+0i1bCr5Qdrkjjqj+PqOSdxk1tqOa0V3eyzwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkNRe70OpVGytvx137QtHZU754eOl1Kht55mlF+1deXto4F2GnOLF3U9+A5syTAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAqtXr9XpTX4JtzVlbth+0X+Pc49344RPVt2ccUXZ2rWwOFPKkAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCS11zwF71ZuP/ClY9W3rZu3abo7BsvGlR4m5bpvueqb/fdt+zsj3Yr27N78aQAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJDKXjzTSL7z07L9fTMfr7xdvmJT0dm//e3mytutb79RdPaB3fauvD3u2IFFZ5988j5F+732qr49a+R/FJ391PTPF+1L/PLn36m8PfeC0UVnb9y4tmj/xqb1lberV60qOrtb9+6VtyPP7FF0Nvw5nhQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQKrV6/V6Yxw8Y1H17d+ffXnR2evm/WfBuuz1AhHVX10Q8Wbh2Z2qT/c+pejkT40eVbTfZ5/qr8W4/evnFp0d8VjhvrEcW7hfXrhfU7Atew3J3478UuXt5ZPGFJ19wsFFc3YznhQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKjvfsIgJbHkwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIA6f8AXKIfnRE7lfgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet-121"
      ],
      "metadata": {
        "id": "E-g9cJlGxb4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        growth_rate, # 出力の次元の成長率\n",
        "        drop_rate,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels) # チャンネルごとでバッチ正規化\n",
        "        self.relu1 = nn.ReLU(inplace=True) # inplace=Trueによりメモリ節約\n",
        "        self.conv1 = nn.Conv2d(in_channels, growth_rate * 4, kernel_size=1, bias=False) # 1*1 conv\n",
        "        self.norm2 = nn.BatchNorm2d(growth_rate * 4)\n",
        "\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(growth_rate * 4, growth_rate, kernel_size=3, padding=1, bias=False) # 3*3 conv\n",
        "        self.dropout = nn.Dropout(p=drop_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat(x, 1) # チャンネル方向で連結 -> ResNetでは加算だった、全ての前の層のデータを利用\n",
        "        x = self.norm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = self.norm2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x # 出力 -> この後連結され、特徴量次元が成長\n",
        "\n",
        "class DenseBlock(nn.ModuleDict): # nn.ModuleDictを使うことで名前で管理できる\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        in_channels,\n",
        "        growth_rate,\n",
        "        drop_rate,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = DenseLayer(\n",
        "                in_channels + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "            )\n",
        "            self.add_module(f\"denselayer{i + 1}\", layer) # denselayer1, denselayer2, ...\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x = [x0] # これまでの特徴マップを連結したリスト\n",
        "        for name, layer in self.items():\n",
        "            out = layer(x)\n",
        "            x.append(out)\n",
        "\n",
        "        return torch.cat(x, 1) # 出力を連結\n",
        "\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.norm = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False) # 1*1 conv\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2) # pooling, padding=False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 growth_rate,\n",
        "                 block_config,\n",
        "                 input_channels = 3, # 白黒画像はチャンネル数1\n",
        "                 drop_rate=0,\n",
        "                 num_classes=10,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        # エンコーダー\n",
        "        self.input_features = nn.Sequential()\n",
        "        self.features = nn.Sequential()\n",
        "        self.gap_features = nn.Sequential()\n",
        "\n",
        "        # 入力の畳み込み\n",
        "        self.input_features.add_module(\"conv0\", nn.Conv2d(input_channels, growth_rate * 2, kernel_size=7, stride=2, padding=3, bias=False)) # size=[H/2, W/2]\n",
        "        self.input_features.add_module(\"norm0\", nn.BatchNorm2d(growth_rate * 2))\n",
        "        self.input_features.add_module(\"relu0\", nn.ReLU(inplace=True))\n",
        "        self.input_features.add_module(\"pool0\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) # max pooling, size=[H/4, W/4]\n",
        "\n",
        "        # DenseBlock + Transition Layer\n",
        "        # size=[H/4, W/4] -> [H/32, W/32]\n",
        "        in_channels = growth_rate * 2\n",
        "        # print(in_channels)\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                in_channels=in_channels,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate\n",
        "            )\n",
        "            self.features.add_module(f\"denseblock{i + 1}\", block)\n",
        "\n",
        "            # 特徴量次元を更新\n",
        "            in_channels += growth_rate * num_layers\n",
        "\n",
        "            # 最後の Dense Block でない場合は、Transition Layer を追加\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = TransitionLayer(in_channels=in_channels, out_channels=in_channels // 2)\n",
        "                self.features.add_module(f\"transition{i + 1}\", trans)\n",
        "                in_channels = in_channels // 2\n",
        "                # print(i, in_channels)\n",
        "\n",
        "            self.gap_features.add_module(\"norm5\", nn.BatchNorm2d(in_channels))\n",
        "            self.gap_features.add_module(\"relu5\", nn.ReLU(inplace=True))\n",
        "            self.gap_features.add_module(\"pool5\", nn.AdaptiveAvgPool2d((1, 1))) # Global Average Pooling, size=[1, 1]\n",
        "\n",
        "            self.classifier = nn.Linear(in_channels, num_classes)\n",
        "\n",
        "            # 重みを初期化する。\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_features(x)\n",
        "        x = self.features(x)\n",
        "        x = self.gap_features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "9l7Drad0xegt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train eval"
      ],
      "metadata": {
        "id": "zmcdIt3eP3Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# model\n",
        "model = DenseNet(config.growth_rate, config.block_config)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss function\n",
        "criterion = F.cross_entropy\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "# schedular\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "# save path\n",
        "os.makedirs(\"models\", exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUl1LT2ANswY",
        "outputId": "8f3a19c7-3bf4-4cdf-bb71-f75ab268a6f8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "0 128\n",
            "1 256\n",
            "2 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "startEpoch = 0\n",
        "\n",
        "# エポックごとの損失平均や正答率平均を保存\n",
        "epoch_losses = []\n",
        "epoch_accs = []\n",
        "epoch_val_losses = []\n",
        "epoch_val_accs = []\n",
        "val_loss_best = float('inf')\n",
        "\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(config.num_epochs):\n",
        "    model.train()\n",
        "    # エポック内の損失平均や正答率平均を計算\n",
        "    epoch_o_loss = []\n",
        "    epoch_o_acc = []\n",
        "    epoch_val_o_loss = []\n",
        "    epoch_val_o_acc = []\n",
        "\n",
        "    with tqdm(train_loader) as pbar:\n",
        "        pbar.set_description(f'[エポック {epoch + 1}]')\n",
        "\n",
        "        for x, y in pbar:\n",
        "            # データをモデルと同じデバイスに転送\n",
        "            x = x.to(config.device) # images [B, C, H, W]\n",
        "            y = y.to(config.device) # labels [B]\n",
        "\n",
        "            # パラメータの勾配をリセット\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 順伝播\n",
        "            y_pred = model(x)\n",
        "\n",
        "            # 学習データに対する損失と正確度を計算\n",
        "            loss = criterion(y_pred, y)\n",
        "            accuracy = (y_pred.argmax(dim=1) == \\\n",
        "                        y).float().mean()\n",
        "\n",
        "            # 誤差逆伝播\n",
        "            loss.backward()\n",
        "\n",
        "            # パラメータの更新\n",
        "            optimizer.step()\n",
        "\n",
        "            # 損失を保存\n",
        "            epoch_o_loss.append(loss.item()) # スケールはF.cross_entropy内で正規化されている\n",
        "            epoch_o_acc.append(accuracy.item())\n",
        "            pbar.set_postfix({\n",
        "                'loss': torch.Tensor(epoch_o_loss).mean().item(),\n",
        "                'accuracy': torch.Tensor(epoch_o_acc).mean().item()})\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with tqdm(val_loader) as pbar:\n",
        "\n",
        "            for x, y in pbar:\n",
        "                # データをモデルと同じデバイスに転送\n",
        "                x = x.to(config.device) # images [B, C, H, W]\n",
        "                y = y.to(config.device) # labels [B]\n",
        "\n",
        "                # 順伝播\n",
        "                y_pred = model(x)\n",
        "\n",
        "                # 学習データに対する損失と正確度を計算\n",
        "                loss = criterion(y_pred, y)\n",
        "                accuracy = (y_pred.argmax(dim=1) == \\\n",
        "                            y).float().mean()\n",
        "\n",
        "                # 移動平均を計算して表示\n",
        "                epoch_val_o_loss.append(loss.item())\n",
        "                epoch_val_o_acc.append(accuracy.item())\n",
        "                pbar.set_postfix({\n",
        "                    'val_loss': torch.Tensor(epoch_val_o_loss).mean().item(),\n",
        "                    'val_accuracy': torch.Tensor(epoch_val_o_acc).mean().item()})\n",
        "\n",
        "    # 損失の保存\n",
        "    epoch_loss = torch.Tensor(epoch_o_loss).mean().item()\n",
        "    epoch_acc = torch.Tensor(epoch_o_acc).mean().item()\n",
        "    epoch_val_loss = torch.Tensor(epoch_val_o_loss).mean().item()\n",
        "    epoch_val_acc = torch.Tensor(epoch_val_o_acc).mean().item()\n",
        "\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    epoch_accs.append(epoch_acc)\n",
        "    epoch_val_losses.append(epoch_val_loss)\n",
        "    epoch_val_accs.append(epoch_val_acc)\n",
        "\n",
        "    print(f'検証　: loss = {epoch_val_loss:.3f}, '\n",
        "            f'accuracy = {epoch_val_acc:.3f}')\n",
        "\n",
        "    # より良い検証結果が得られた場合、モデルを記録\n",
        "    if epoch_val_loss < val_loss_best:\n",
        "        val_loss_best = epoch_val_loss\n",
        "        model_best = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # エポック終了時にスケジューラを更新\n",
        "    scheduler.step()\n",
        "\n",
        "    # モデルパラメータを保存\n",
        "    torch.save({\"epoch\": epoch+1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"best_model_dict\": model_best,\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
        "                \"epoch_losses\": epoch_losses,\n",
        "                \"epoch_accs\": epoch_accs,\n",
        "                \"epoch_val_losses\": epoch_val_losses,\n",
        "                \"epoch_val_accs\": epoch_val_accs,\n",
        "                \"best_loss\": val_loss_best\n",
        "                }, f\"models/{epoch}_{best_loss}.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpOPeO2rOJyv",
        "outputId": "8ca7dbad-692f-4822-bbd1-c0d8a81304cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 1]: 100%|██████████| 2500/2500 [03:25<00:00, 12.17it/s, loss=2.12, accuracy=0.225]\n",
            "100%|██████████| 625/625 [00:20<00:00, 30.84it/s, val_loss=1.97, val_accuracy=0.296]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.972, accuracy = 0.296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 2]: 100%|██████████| 2500/2500 [03:23<00:00, 12.27it/s, loss=1.9, accuracy=0.313]\n",
            "100%|██████████| 625/625 [00:19<00:00, 31.89it/s, val_loss=1.83, val_accuracy=0.347]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.827, accuracy = 0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 3]: 100%|██████████| 2500/2500 [03:22<00:00, 12.36it/s, loss=1.79, accuracy=0.349]\n",
            "100%|██████████| 625/625 [00:19<00:00, 31.36it/s, val_loss=1.74, val_accuracy=0.376]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.738, accuracy = 0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 4]: 100%|██████████| 2500/2500 [03:23<00:00, 12.30it/s, loss=1.72, accuracy=0.373]\n",
            "100%|██████████| 625/625 [00:20<00:00, 31.21it/s, val_loss=1.68, val_accuracy=0.391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.679, accuracy = 0.391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 5]:  46%|████▌     | 1141/2500 [01:32<01:45, 12.83it/s, loss=1.69, accuracy=0.383]"
          ]
        }
      ]
    }
  ]
}