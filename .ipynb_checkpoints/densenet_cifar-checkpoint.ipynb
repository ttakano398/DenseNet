{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-ICsaTbEC5w"
   },
   "source": [
    "# Description: Classification tutorial using DenseNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK03d6beIACu"
   },
   "outputs": [],
   "source": [
    "class MyConfig:\n",
    "    def __init__(self):\n",
    "        # Transform\n",
    "        self.p_blur = 0.5 # ぼかしを入れる確率\n",
    "\n",
    "        # condition\n",
    "        self.batch_size = 128\n",
    "        self.lr = 1e-4 # 5e-6\n",
    "        self.device = \"cuda\"\n",
    "        self.num_epochs = 100\n",
    "        self.num_workers = 0\n",
    "\n",
    "        # Data\n",
    "        self.val_ratio = 0.2\n",
    "\n",
    "        # DenseNet-121\n",
    "        self.growth_rate=16 # default (DenseNet-121): 32\n",
    "        self.block_config=(1, 2, 4, 3) # DenseNet-25 / default (DenseNet-121): (6, 12, 24, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjzoiU3-EeJQ"
   },
   "source": [
    "## モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcR0R_huEgxP"
   },
   "outputs": [],
   "source": [
    "config = MyConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaRK-YJVEMh8"
   },
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nwV69l-Gquj"
   },
   "outputs": [],
   "source": [
    "# インポート\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJPXzXDbHvBM"
   },
   "outputs": [],
   "source": [
    "class RandomBlur(torch.nn.Module):\n",
    "    def __init__(self, p=config.p_blur):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.blur = transforms.GaussianBlur(kernel_size=3)\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1) < self.p: # True\n",
    "            return self.blur(img)\n",
    "        return img # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx65g223GwlQ"
   },
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoBfMhGdIfzi"
   },
   "outputs": [],
   "source": [
    "# # Transform\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
    "#     transforms.Normalize(mean=[0.445], std=[0.269]),  # 正規化\n",
    "#     RandomBlur(), # Random Blur\n",
    "# ])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
    "#     transforms.Normalize(mean=[0.445], std=[0.269]),  # 正規化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4nDBkupHDC6"
   },
   "outputs": [],
   "source": [
    "# # MNIST を取得\n",
    "# # Train\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root='data',          # データを保存するディレクトリ\n",
    "#     train=True,           # 学習用データを取得\n",
    "#     download=True,        # データがない場合はダウンロードする\n",
    "#     transform=train_transform,  # 画像データの変換方法を指定\n",
    "# )\n",
    "\n",
    "# # Validation\n",
    "# val_dataset = datasets.MNIST(\n",
    "#     root='data',\n",
    "#     train=True,\n",
    "#     download=True,\n",
    "#     transform=test_transform,\n",
    "# )\n",
    "\n",
    "# # test\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root='data',\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=test_transform,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ttRfuQNJQug"
   },
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnctevecD_As"
   },
   "outputs": [],
   "source": [
    "# Transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),  # 正規化\n",
    "    RandomBlur(), # Random Blur\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Random Flip\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  $ Random Crop\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),        # テンソルに変換 & 0-255 の値を 0-1 に変換\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),  # 正規化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yugesBA5HpyQ",
    "outputId": "613b3474-2d71-4eb2-82ff-1d98e280a670"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:13<00:00, 13.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 を取得\n",
    "# Train\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root='data',          # データを保存するディレクトリ\n",
    "    train=True,           # 学習用データを取得\n",
    "    download=True,        # データがない場合はダウンロードする\n",
    "    transform=train_transform,  # 画像データの変換方法を指定\n",
    ")\n",
    "\n",
    "# Validation\n",
    "val_dataset = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=test_transform,\n",
    ")\n",
    "\n",
    "# test\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QungSkpMMqDw"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "データセットを分割するための2つの排反なインデックス集合を生成する関数\n",
    "dataset    : 分割対象のデータセット\n",
    "ratio      : 1つ目のセットに含めるデータ量の割合\n",
    "random_seed: 分割結果を不変にするためのシード\n",
    "'''\n",
    "def generate_subset(dataset: Dataset, ratio: float,\n",
    "                    random_seed: int=0):\n",
    "    # サブセットの大きさを計算\n",
    "    size = int(len(dataset) * ratio)\n",
    "\n",
    "    indices = list(range(len(dataset)))\n",
    "\n",
    "    # 二つのセットに分ける前にシャッフル\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # セット1とセット2のサンプルのインデックスに分割\n",
    "    indices1, indices2 = indices[:size], indices[size:]\n",
    "\n",
    "    return indices1, indices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyDxqWWSKQ5j",
    "outputId": "79a48db9-4538-49bf-ffa6-5b8b37c6f1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習セットのサンプル数　: 40000\n",
      "検証セットのサンプル数　: 10000\n",
      "テストセットのサンプル数: 10000\n"
     ]
    }
   ],
   "source": [
    "# Train, val 分割\n",
    "val_set, train_set = generate_subset(\n",
    "    train_dataset, config.val_ratio)\n",
    "\n",
    "print(f'学習セットのサンプル数　: {len(train_set)}')\n",
    "print(f'検証セットのサンプル数　: {len(val_set)}')\n",
    "print(f'テストセットのサンプル数: {len(test_dataset)}')\n",
    "\n",
    "# インデックス集合から無作為にインデックスをサンプルするサンプラー\n",
    "train_sampler = SubsetRandomSampler(train_set)\n",
    "\n",
    "# DataLoaderを生成\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size, sampler=train_sampler, num_workers=config.num_workers)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.batch_size, sampler=val_set, num_workers=config.num_workers)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=config.batch_size, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "YmjU2ByUM4d9",
    "outputId": "725dc3f6-62f0-4f31-a37e-3ddacaea1bde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.9667418..2.6400003].\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataloader確認\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    # print(images.shape) # [B, C, H, W]\n",
    "    # print(labels.shape) # [B]\n",
    "\n",
    "    image_0 = images[0]\n",
    "    label_0 = labels[0]\n",
    "\n",
    "    # tensorをnumpyに変換し、チャンネル次元を削除\n",
    "    # plt.imshow(image_0.squeeze(), cmap='gray') # for MNIST\n",
    "    plt.imshow(image_0.permute(1, 2, 0)) # for CIFAR-10\n",
    "    plt.title(f\"Label: {label_0}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-g9cJlGxb4O"
   },
   "source": [
    "## DenseNet-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9l7Drad0xegt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        growth_rate, # 出力の次元の成長率\n",
    "        drop_rate,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels) # チャンネルごとでバッチ正規化\n",
    "        self.relu1 = nn.ReLU(inplace=True) # inplace=Trueによりメモリ節約\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_rate * 4, kernel_size=1, bias=False) # 1*1 conv\n",
    "        self.norm2 = nn.BatchNorm2d(growth_rate * 4)\n",
    "\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(growth_rate * 4, growth_rate, kernel_size=3, padding=1, bias=False) # 3*3 conv\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat(x, 1) # チャンネル方向で連結 -> ResNetでは加算だった、全ての前の層のデータを利用\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x # 出力\n",
    "\n",
    "class DenseBlock(nn.ModuleDict): # nn.ModuleDictを使うことで名前で管理できる\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        in_channels,\n",
    "        growth_rate,\n",
    "        drop_rate,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = DenseLayer(\n",
    "                in_channels + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "            )\n",
    "            self.add_module(f\"denselayer{i + 1}\", layer) # denselayer1, denselayer2, ...\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x = [x0] # これまでの特徴マップを連結したリスト\n",
    "        for name, layer in self.items():\n",
    "            out = layer(x)\n",
    "            x.append(out) # DenseLayerの出力のリストを作成 -> 入力後に特徴量を連結\n",
    "\n",
    "        return torch.cat(x, 1) # 最終的に出力を連結\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False) # 1*1 conv\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2) # pooling, padding=False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 growth_rate,\n",
    "                 block_config,\n",
    "                 input_channels = 3, # 白黒画像はチャンネル数1\n",
    "                 drop_rate=0,\n",
    "                 num_classes=10,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        # エンコーダー\n",
    "        self.input_features = nn.Sequential()\n",
    "        self.features = nn.Sequential()\n",
    "        self.gap_features = nn.Sequential()\n",
    "\n",
    "        # 入力の畳み込み\n",
    "        self.input_features.add_module(\"conv0\", nn.Conv2d(input_channels, growth_rate * 2, kernel_size=7, stride=2, padding=3, bias=False)) # size=[H/2, W/2]\n",
    "        self.input_features.add_module(\"norm0\", nn.BatchNorm2d(growth_rate * 2))\n",
    "        self.input_features.add_module(\"relu0\", nn.ReLU(inplace=True))\n",
    "        self.input_features.add_module(\"pool0\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) # max pooling, size=[H/4, W/4]\n",
    "\n",
    "        # DenseBlock + Transition Layer\n",
    "        # size=[H/4, W/4] -> [H/32, W/32]\n",
    "        in_channels = growth_rate * 2\n",
    "        # print(in_channels)\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                in_channels=in_channels,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate\n",
    "            )\n",
    "            self.features.add_module(f\"denseblock{i + 1}\", block)\n",
    "\n",
    "            # 特徴量次元を更新\n",
    "            in_channels += growth_rate * num_layers\n",
    "\n",
    "            # 最後の Dense Block でない場合は、Transition Layer を追加\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = TransitionLayer(in_channels=in_channels, out_channels=in_channels // 2)\n",
    "                self.features.add_module(f\"transition{i + 1}\", trans)\n",
    "                in_channels = in_channels // 2\n",
    "                # print(i, in_channels)\n",
    "\n",
    "            self.gap_features.add_module(\"norm5\", nn.BatchNorm2d(in_channels))\n",
    "            self.gap_features.add_module(\"relu5\", nn.ReLU(inplace=True))\n",
    "            self.gap_features.add_module(\"pool5\", nn.AdaptiveAvgPool2d((1, 1))) # Global Average Pooling, size=[1, 1]\n",
    "\n",
    "            self.classifier = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "            # 重みを初期化する。\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_features(x)\n",
    "        x = self.features(x)\n",
    "        x = self.gap_features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmcdIt3eP3Lg"
   },
   "source": [
    "## Train eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUl1LT2ANswY"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# model\n",
    "model = DenseNet(config.growth_rate, config.block_config)\n",
    "model.to(config.device)\n",
    "\n",
    "# loss function\n",
    "criterion = F.cross_entropy\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# schedular\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# save path\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mpOPeO2rOJyv",
    "outputId": "98f64777-c9d0-4034-a1ac-97f921956709"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   0%|          | 1/2500 [00:00<16:43,  2.49it/s, loss=2.35, accuracy=0.0938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   0%|          | 5/2500 [00:00<05:06,  8.15it/s, loss=2.26, accuracy=0.156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   0%|          | 9/2500 [00:01<03:52, 10.72it/s, loss=2.23, accuracy=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   0%|          | 11/2500 [00:01<03:36, 11.52it/s, loss=2.22, accuracy=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 15/2500 [00:01<03:17, 12.60it/s, loss=2.22, accuracy=0.196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 17/2500 [00:01<03:14, 12.74it/s, loss=2.23, accuracy=0.194]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 21/2500 [00:01<03:11, 12.96it/s, loss=2.23, accuracy=0.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3125, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 23/2500 [00:02<03:06, 13.26it/s, loss=2.22, accuracy=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3125, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 25/2500 [00:02<03:05, 13.32it/s, loss=2.22, accuracy=0.185]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 27/2500 [00:02<03:42, 11.13it/s, loss=2.22, accuracy=0.19] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|          | 31/2500 [00:02<03:57, 10.38it/s, loss=2.22, accuracy=0.188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2500, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|▏         | 35/2500 [00:03<03:29, 11.77it/s, loss=2.22, accuracy=0.189]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   1%|▏         | 37/2500 [00:03<03:24, 12.06it/s, loss=2.22, accuracy=0.186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 41/2500 [00:03<03:11, 12.86it/s, loss=2.22, accuracy=0.181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 43/2500 [00:03<03:16, 12.49it/s, loss=2.23, accuracy=0.176]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 47/2500 [00:04<03:07, 13.11it/s, loss=2.23, accuracy=0.172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 49/2500 [00:04<03:08, 13.04it/s, loss=2.24, accuracy=0.169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 53/2500 [00:04<03:03, 13.35it/s, loss=2.23, accuracy=0.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 55/2500 [00:04<03:03, 13.30it/s, loss=2.23, accuracy=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 59/2500 [00:05<03:03, 13.32it/s, loss=2.23, accuracy=0.168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   2%|▏         | 61/2500 [00:05<03:02, 13.37it/s, loss=2.23, accuracy=0.168]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 65/2500 [00:05<03:01, 13.42it/s, loss=2.23, accuracy=0.169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 67/2500 [00:05<02:59, 13.53it/s, loss=2.24, accuracy=0.167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 71/2500 [00:05<03:01, 13.35it/s, loss=2.24, accuracy=0.165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.0625, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 73/2500 [00:06<03:00, 13.42it/s, loss=2.24, accuracy=0.166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 77/2500 [00:06<02:59, 13.49it/s, loss=2.24, accuracy=0.166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 79/2500 [00:06<02:57, 13.62it/s, loss=2.24, accuracy=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4375, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 83/2500 [00:06<03:02, 13.24it/s, loss=2.24, accuracy=0.171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   3%|▎         | 85/2500 [00:07<03:00, 13.38it/s, loss=2.24, accuracy=0.172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.3125, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   4%|▎         | 89/2500 [00:07<02:58, 13.53it/s, loss=2.24, accuracy=0.171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   4%|▎         | 91/2500 [00:07<02:59, 13.44it/s, loss=2.24, accuracy=0.172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.1875, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   4%|▍         | 95/2500 [00:07<02:57, 13.56it/s, loss=2.24, accuracy=0.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   4%|▍         | 97/2500 [00:07<03:03, 13.12it/s, loss=2.24, accuracy=0.17] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n",
      "tensor(0.1250, device='cuda:0')\n",
      "tensor(0.3750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[エポック 1]:   4%|▍         | 99/2500 [00:08<03:14, 12.34it/s, loss=2.24, accuracy=0.169]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-70c3e9aae006>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[エポック {epoch + 1}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# データをモデルと同じデバイスに転送\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# images [B, C, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mflipped\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \"\"\"\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "startEpoch = 0\n",
    "\n",
    "# エポックごとの損失平均や正答率平均を保存\n",
    "epoch_losses = []\n",
    "epoch_accs = []\n",
    "epoch_val_losses = []\n",
    "epoch_val_accs = []\n",
    "val_loss_best = float('inf')\n",
    "\n",
    "\n",
    "# epoch loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # epoch内の累積損失・累積正解数・累積サンプル数\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    with tqdm(train_loader) as pbar:\n",
    "        pbar.set_description(f'[Epoch {epoch}]')\n",
    "\n",
    "        for x, y in pbar:\n",
    "            x = x.to(config.device) # images [B, C, H, W]\n",
    "            y = y.to(config.device) # labels [B]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 推論\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # trainに対する損失と正確度を計算\n",
    "            loss = criterion(y_pred, y)  # バッチ平均損失\n",
    "            preds = y_pred.argmax(dim=1)\n",
    "            correct = (preds == y).sum().item()  # 正解数\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 損失・正解数・サンプル数を累積\n",
    "            running_loss += loss.item() * x.size(0)  # バッチ平均損失*バッチサイズ\n",
    "            running_correct += correct               # 正解数\n",
    "            running_total += x.size(0)               # バッチサイズ\n",
    "\n",
    "            # 進捗表示\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / running_total,      # 平均損失\n",
    "                'accuracy': running_correct / running_total # 平均正答率\n",
    "            })\n",
    "\n",
    "    # epochの平均損失・正答率を保存\n",
    "    epoch_loss = running_loss / running_total\n",
    "    epoch_acc = running_correct / running_total\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    val_running_total = 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader) as pbar:\n",
    "            for x, y in pbar:\n",
    "                x = x.to(config.device) # images [B, C, H, W]\n",
    "                y = y.to(config.device) # labels [B]\n",
    "\n",
    "                # 推論\n",
    "                y_pred = model(x)\n",
    "\n",
    "                # valに対する損失と正確度を計算\n",
    "                loss = criterion(y_pred, y)\n",
    "                preds = y_pred.argmax(dim=1)\n",
    "                correct = (preds == y).sum().item()  # 正解数\n",
    "\n",
    "                # 損失・正解数・サンプル数を累積\n",
    "                val_running_loss += loss.item() * x.size(0)  # バッチ平均損失*バッチサイズ\n",
    "                val_running_correct += correct               # 正解数\n",
    "                val_running_total += x.size(0)               # バッチサイズ\n",
    "\n",
    "                # 進捗表示\n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': val_running_loss / val_running_total,\n",
    "                    'val_accuracy': val_running_correct / val_running_total\n",
    "                })\n",
    "\n",
    "    # valデータの平均損失・正答率を保存\n",
    "    epoch_val_loss = val_running_loss / val_running_total\n",
    "    epoch_val_acc = val_running_correct / val_running_total\n",
    "\n",
    "    # epochごとの損失・正答率を保存\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_accs.append(epoch_acc)\n",
    "    epoch_val_losses.append(epoch_val_loss)\n",
    "    epoch_val_accs.append(epoch_val_acc)\n",
    "\n",
    "    # best model\n",
    "    if epoch_val_loss < val_loss_best:\n",
    "        val_loss_best = epoch_val_loss\n",
    "        model_best = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # エポック終了時にスケジューラを更新\n",
    "    scheduler.step()\n",
    "\n",
    "    # モデルパラメータを保存\n",
    "    torch.save({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"best_model_dict\": model_best,\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"epoch_losses\": epoch_losses,\n",
    "        \"epoch_accs\": epoch_accs,\n",
    "        \"epoch_val_losses\": epoch_val_losses,\n",
    "        \"epoch_val_accs\": epoch_val_accs,\n",
    "        \"best_loss\": val_loss_best\n",
    "    }, f\"models/{epoch+1}_{round(val_loss_best, 3)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータでの評価\n",
    "model.load_state_dict(model_best)  # ベストモデルをロード\n",
    "model.eval()\n",
    "test_running_loss = 0.0\n",
    "test_running_correct = 0\n",
    "test_running_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader) as pbar:\n",
    "        for x, y in pbar:\n",
    "            x = x.to(config.device)  # images [B, C, H, W]\n",
    "            y = y.to(config.device)  # labels [B]\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            preds = y_pred.argmax(dim=1)\n",
    "            correct = (preds == y).sum().item()\n",
    "\n",
    "            # 損失・正解数・サンプル数を累積\n",
    "            test_running_loss += loss.item() * x.size(0)  # バッチ損失*バッチサイズ\n",
    "            test_running_correct += correct               # 正解数\n",
    "            test_running_total += x.size(0)               # バッチサイズ\n",
    "\n",
    "            # 進捗表示\n",
    "            pbar.set_postfix({\n",
    "                'test_loss': test_running_loss / test_running_total,\n",
    "                'test_accuracy': test_running_correct / test_running_total\n",
    "            })\n",
    "\n",
    "# testの平均損失・正答率を計算\n",
    "test_loss = test_running_loss / test_running_total\n",
    "test_acc = test_running_correct / test_running_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータでの評価\n",
    "model.load_state_dict(model_best)  # ベストモデルをロード\n",
    "model.eval()\n",
    "test_running_loss = 0.0\n",
    "test_running_correct = 0\n",
    "test_running_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader) as pbar:\n",
    "        for x, y in pbar:\n",
    "            x = x.to(config.device)  # images [B, C, H, W]\n",
    "            y = y.to(config.device)  # labels [B]\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            preds = y_pred.argmax(dim=1)\n",
    "            correct = (preds == y).sum().item()\n",
    "\n",
    "            # 損失・正解数・サンプル数を累積\n",
    "            test_running_loss += loss.item() * x.size(0)  # バッチ損失*バッチサイズ\n",
    "            test_running_correct += correct               # 正解数\n",
    "            test_running_total += x.size(0)               # バッチサイズ\n",
    "\n",
    "            # 進捗表示\n",
    "            pbar.set_postfix({\n",
    "                'test_loss': test_running_loss / test_running_total,\n",
    "                'test_accuracy': test_running_correct / test_running_total\n",
    "            })\n",
    "\n",
    "# testの平均損失・正答率を計算\n",
    "test_loss = test_running_loss / test_running_total\n",
    "test_acc = test_running_correct / test_running_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
